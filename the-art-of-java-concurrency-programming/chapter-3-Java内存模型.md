### Java 内存模型

#### Java 内存模型的基础
##### 并发编程模型的两个关键问题
在并发编程中需要处理两个关键问题: 线程之间如何通信以及线程之间如何同步; 通信是指线程之间以何种机制来交换信息, 在命令式编程中, 线程之间的通信机制有两种: 共享内存和消息传递  
在共享内存的并发模型里, 线程之间共享程序的公共状态, 通过读写内存中的公共状态进行隐式通信; 在消息传递的并发模型里, 线程之间没有公共状态, 线程之间必须通过发送消息来显示进行通信  
同步是值程序中用于控制不同线程间操作发生相对顺序的机制, 在共享内存并发模型里, 同步是显式进行的; 在消息传递的模型里, 由于消息的发送必须在消息接收之前, 因此同步是隐式进行的  
Java 的并发采用的是共享内存模型, Java 线程之间的通信是隐式进行的

##### Java 内存模型的抽象结构
在 Java 中所有的实例域, 静态域, 数组元素都存储在堆内存中, 堆内存在线程之间共享; 局部变量, 方法定义参数, 异常处理器参数不会在线程之间共享, 因此不会有内存可见性问题, 也不受内存模型的影响  
Java 线程之间的通信由 Java 内存模型 (JMM) 控制, JMM 决定了一个线程对共享变量的写入何时对另一个线程可见; JMM 定义了线程和主内存之间的抽象关系: 线程之间的共享变量存储在主内存 (Main Memory) 中, 每个线程都有一个私有的本地内存 (Local Memory), 本地内存中存储了该线程以读/写共享变量的副本 (本地内存只是一个抽象, 并不存在)
```
-----------                   -----------
|  线程 A  |                  |  线程 B  |
-----------                   -----------
    |                              |
    V                              V
-------------                 -------------
|本地内存 A  |                 |本地内存 B  |
|共享变量副本|                 |共享变量副本 |  
-------------                 -------------    
    |                              |
    V                              V
--------------------------------------------
|                 主内存                    |
|                共享变量                   |
--------------------------------------------
```
如果线程 A 和线程 B 要通信的话, 必须通过以下两个步骤
- 线程 A 把本地内存 A 更新过的共享变量刷新到主内存中去
- 线程 B 到主内存中读取线程 A 之前更新过的变量
从整体上来看, 以上两个步骤实质上是线程 A 向线程 B 发消息, 而且这个通信必须经过主内存; JMM 通过控制主内存与每个线程的本地内存之间的交互, 来为 Java 程序提供内存可见性

##### 从源代码到指令序列的重排序
在执行程序时, 为了提高性能, 编译器和处理器常会对指令做重新排序, 分以下三种
- 编译器优化的重排序
- 指令级并行的重排序
- 内存系统的重排序
对于编译器, JMM 的编译器重排序规则会禁止特定类型的编译器重排序; 对于处理器, JMM 的处理器重排序规则会要求 Java 编译器在生成指令序列时, 插入特定类型的内存屏障指令, 同步内存屏障指令来禁止特定类型的处理器重排序; JMM 属于语言级的内存模型, 确保在不同的编译器和不同的处理器平台上, 通过禁止特定类型的编译器和处理器重排序, 提供一致的内存可见性保证

##### 并发编程模型的分类
常见处理器的重排序规则

| 处理器\规则 | Load-Load | Load-Store | Store-Store | Store-Load | 数据依赖 |
| :------------- | :------------- | :------------- | :------------- | :------------- | :------------- |
| SPARC-TSO | N | N | N | Y | N |
| x86 | N | N | N | Y | N |
| IA64 | Y | Y | Y | Y | N |
| PowerPC | Y | Y | Y | Y | N |

常见的处理器都允许 Store-Load 重排序, 都不允许存在数据依赖的操作做重排序, SPARC-TSO 和 x86 拥有相对较强的处理器内存模型, 仅允许对写 - 读操作做重排序 (因为都用了写缓冲区); 为了保证内存可见性, Java 编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序; JMM 把内存屏障指令分为 4 类

| 屏障类型 | 指令示例 | 说明 |
| :------------- | :------------- | :------------- |
| LoadLoad Barriers | Load1;LoadLoad;Load2 |确保 Load1 数据的装载先于 Load2 及后续装载指令的装载|
| StoreStore Barriers | Store1;StoreStore;Store2 |确保 Store1 数据对其他处理器可见 (刷新到内存) 先于 Store2 及后续装载指令的装载|
| LoadStore Barriers | Load1;LoadStore;Store2 |确保 Load1 数据的装载先于 Store2 及后续装载指令的装载|
| StoreLoad Barriers | Store1;StoreLoad;Load2 |确保 Store1 数据对其他处理器可见 (刷新到内存) 先于 Load2 及后续装载指令的装载; StoreLoad Barriers 会使该屏障之前的所有内存访问指令 (存储和装载指令) 完成之后, 才执行该屏障之后的内存访问指令|

StoreLoad Barriers 是一个 "全能型" 的屏障, 它同时具有其他 3 个屏障的效果, 现代的多处理器大多支持此屏障; 执行该屏障开销会很昂贵, 因为当前处理器通常要把写缓冲区的数据全部刷新到内存中

##### happens-before 简介
JDK 5 开始 Java 使用 JSR-133 内存模型, JSR-133 中使用 happens-before 的概念來阐述操作之间的可见性; 在 JMM 中如果一个操作执行的结果需要对另一个操作可见, 那么这两个操作之间必须要存在 happens-before 关系; 这里的两个操作可以在一个线程中也可以不在一个线程中
- 程序顺序规则: 一个线程中的每个操作, happens-before 于该线程中的任意后续操作
- 监视器锁规则: 对一个锁解锁, happens-before 于随后对这个锁的加锁
- volatile 变量规则: 对一个 volatile 域的写, happens-before 于任意后续对这个 volatile 域的读
- 传递性: 如果 A happens-before B, B happens-before C, 那么 A happens-before C

#### 重排序
重排序是编译器和处理器优化程序性能而对指令序列进行重排序的一种手段

##### 数据依赖性
如果两个操作访问同一个变量, 且这两个操作中有一个为写操作, 此时这两个操作之间就存在数据依赖性

| 名称 | 代码示例 | 说明 |
| :------------- | :------------- | :------------- |
| 写后读 | a = 1; b = a; | 写一个变量后再读这个变量 |
| 写后写 | a = 1; a = 2; | 写一个变量后再写这个变量 |
| 读后写 | a = b; b = 1; | 读一个变量后再写这个变量 |

编译器和处理器不会对存在数据依赖的两个操作执行顺序, 这里仅说的是对单个处理器中执行的指令序列和单线程中执行的操作; 不同处理器之间和不同线程之间的数据依赖性不被编译器和处理器考虑

##### as-if-serial 语义
as-if-serial 语义的意思是: 不管怎么重排序, (单线程) 程序的执行结果不能被改变
```
double pi = 3.14; // A
double r = 1.0;  // B
double area = pi * r * r; // C
```
以上代码重排序可能的执行顺序是 A -> B -> C 或者 B -> A -> C; 遵守 as-if-serial 的编译器, runtime, 处理器共同为编写程序的人制造了一个幻觉: 单线程程序是程序的顺序来执行的; as-if-serial 语义使单线程程序员无需担心重排序会干扰, 也无须担心重排序的可见性问题

##### 程序顺序规则
按上面计算圆的面积代码来看
- A happens-before B
- B happens-before C
- A happens-before C

A happens-before B, JMM 并不要求 A 一定要在 B 之前执行, JMM 仅要求前一个操作 (执行结果) 对后一个操作可见, 且前一个操作排在第二个操作之前; 这里操作 A 的执行结果不需要对操作 B 可见, 重排序后的结果与 happens-before 顺序执行的一致; JMM 认为这种重排序并不违法, 允许这种重排序

##### 重排序对多线程的影响
```
class ReorderExample {
    int a = 0;
    boolean flag = false;

    public void writer() {
        a = 1; // 1
        flag = true; // 2
        ...
    }

    public void reader() {
        if (flag) {  // 3
            int i = a;  // 4
            ...
        }
    }
}
```
TODO  

在单线程中, 对存在控制依赖的操作重排序, 不会改变执行结果; 但在多线程中, 对存在控制依赖的操作重排序, 可能会改变程序的执行jie'guo

#### 顺序一致性
顺序一致性内存模型是一个理论参考模型

##### 数据竞争与顺序一致性
当程序未正确同步时, 就可能存在数据竞争; 如果程序是正确同步的, 程序的执行将具有顺序一致性 (Sequentially Consistent), 即程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同

##### 顺序一致性内存模型
顺序一致性内存模型有两大特性
- 一个线程中的所有操作必须按照程序的顺序来执行
- (不管程序是否同步) 所有的线程都只能看到一个单一的操作执行顺序, 在顺序一致性内存模型中, 每个操作都必须原子执行且立刻对所有线程可见

假设有 A, B 两个线程, 每个线程有三步执行, 且使用了监视器锁来做同步, 那么两个线程的执行顺序可能是: A1 -> A2 -> A3 -> B1 -> B2 -> B3; 如果没有使用同步, 执行顺序可能是: B1 -> A1 -> A2 -> B2 -> B3 -> A3; 但是在 JMM 中就没有这种保证, 未同步的程序在 JMM 中不但整体的执行顺序是无序的, 而且所有线程看到的操作执行顺序也可能是不一致的

##### 同步程序的顺序一致性结果
```
class ReorderExample {
    int a = 0;
    boolean flag = false;

    public synchronized void writer() {  // 获得锁
        a = 1;
        flag = true;
        ...
    }  // 释放锁

    public synchronized void reader() {  // 获得锁
        if (flag) {
            int i = a;
            ...
        }
    }   // 释放锁
}
```
顺序一致性模型中, 所有操作完成按照程序的顺序串行执行, 而在 JMM 中临界区的代码可以重新排序, JMM 会在进入临界区和退出临界区的两个关键时间点做一些特别的处理, 使得线程在这两个时间点具有与顺序一致性模型相同的内存视图; JMM 的在事项上的基本方针是: 在不改变 (正确同步的) 程序的执行结果前提下, 尽可能地为编译器和处理器的优化打开方便之门

##### 未同步程序的执行特性
对于未同步或未正确同步的多线程程序, JMM 只提供最小安全性: 线程执行时读取到的值, 要么是之前某个线程写入的值, 要么是默认的值 (0, Null, False), JMM 保证线程读操作读取到的值不会无中生有 (Out of Thin Air) 的冒出来的; 为了实现最小安全性, JVM 在堆上分配对象时, 首先会对内存空间进行清零, 然后才会在上面分配对象; 因此在已清零的内存空间中分配对象时, 域的默认初始化已经完成了  
JVM 不保证未同步的程序的执行结果与该程序在顺序一致性模型中的执行结果一致, 因为想要保证一致, 就要禁止大量编译器和处理器的优化, 这非常影响程序执行的性能; 未同步的程序在两个模型中的执行特性有如下差异
- 顺序一致性模型保证单线程内的操作会按程序的顺序执行, 而 JMM 不保证单线程内操作会按程序的顺序执行
- 顺序一致性模型保证所有线程只能看到一致性的操作执行顺序, 而 JMM 不保证所有线程看到一致的操作执行顺序
- JMM 不保证对 64 位的 long 型和 double 型变量写操作具有原子性, 而顺序一致性模型保证对所有的内存读/写操作都具有原子性

#### volatile 的内存语义
理解 volatile 特性一个好方法是把 volatile 变量的单个读/写, 看成是使用同一个锁对这些单个读/写操作做了同步
```
class VolatileFeaturesExample {
    volatile long vl = 0L;

    public void set(long l) {
        vl = l;
    }

    public void getAndIncrement() {
        vl++;
    }

    public long get() {
        return vl;
    }
}
```
以上程序等价于
```
class VolatileFeaturesExample {
    long vl = 0L;

    public synchronized void set(long l) {
        vl = l;
    }

    public void getAndIncrement() {
        long tmp = get();
        tmp += 1L;
        set(tmp);
    }

    public synchronized long get() {
        return vl;
    }
}
```
简而言之, volatile 变量自身具有以下特性
- 可见性: 对一个 volatile 变量的读, 总是能看到 (任意线程) 对这个 volatile 变量最后的写入
- 原子性: 对任意单个 volatile 变量的读/写具有原子性, 但类似于 volatile++ 这种复合操作不具有原子性

##### volatile 写 - 读建立的 happens-before 关系
从 JSR-133 开始 (即从 JDK5 开始), volatile 变量的写读可以实现线程之间的通信; 从内存语义的角度来说, volatile 的读写与锁的获取和释放有相同的内存语义
```
class VolatileExample {
    int a = 0;
    volatile boolean flag = false;

    public void writer() {
        a = 1;  // 1
        flag = true;  // 2
        ...
    }

    public void reader() {
        if (flag) {  // 3
            int i = a;  // 4
            ...
        }
    }
}
```
假设线程 A 执行 writer() 之后, 线程 B 执行 reader() 方法; 根据 happens-before 规则, 可以建立以下关系
- 根据程序次序规则: 1 happens-before 2, 3 happens-before 4
- 根据 volatile 规则: 2 happens-before 3;
- 根据 happens-before 的传递性规则, 1 happens-before 4

##### volatile 写 - 读的内存语义
- volatile 写的内存语义: 当写一个 volatile 变量时, JMM 会把该线程对应的本地内存中的共享变量值刷新到主内存中
即当线程 A 在写 flag 变量后, 本地内存 A 中被线程 A 更新过的两个共享变量值被刷新到主内存中
- volatile 读的内存语义: 当读一个 volatile 变量时, JMM 会把该线程对应的本地内存置为无效, 线程接下来将从主内存中读取共享变量

如果把 volatile 的写读两个步骤综合起来看, 在读线程 B 读一个 volatile 变量后, 在写线程 A 写一个 volatile 变量之前, 所有可见的共享变量的值都将立即变得对读线程 B 可见

##### volatile 内存语义的实现
