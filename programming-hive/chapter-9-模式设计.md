### 模式设计

#### 按天划分的表
按天划分的表是一种模式, 通常会在表名中加入一个时间戳; 在 Hive 中这种情况下应该使用分区表, 通过 where 子句的表达式来选择查询所需要的指定的分区, 这样查询效率较高而且看起来比较清晰明了

#### 关于分区
Hive 通常要对输入进行全盘扫描, 来满足查询条件; 通过创建很多的分区确实可以优化一些查询, 但同时可能会对包含很多小文件的表查询不利; MapReduce 会将一个作业 (job) 转换为多个任务 (task), 默认情况下每个 task 都是一个新的 JVM 实例, 都需要开启和销毁的开销; 对于小文件, 每个文件都会应对一个 task, 在一些情况下 JVM 的开启和销毁的时间可能会比实际处理数据的时间消耗要长  
因此一个理想的分区方案不应该导致产生太多的分区和文件目录, 并且每个目录下的文件应该足够大, 应该是文件系统中块大小的若干倍; 按时间范围进行分区的一个好的策略就是按照不同的时间粒度来确定合适大小的数据累积量, 另一个解决方案是使对多级别分区; 如果不能够找到好的, 大小相对合适的分区方式的话, 可以考虑分桶存储

#### 唯一键和标准化
关系型数据库通常使用唯一键, 索引和标准化来存储数据集; 然而 Hive 没有主键或基于序列密钥生成的自增主键的概念, 并且支持复杂的数据类型, 所以应避免对其非标准化的数据进行连接操作; 避免标准化的主要原因是为了最小化磁盘寻道, 非标准化的数据允许被扫描或写入到大的, 连续的磁盘存储区域, 从而优化磁盘驱动器的 I/O 性能; 虽然非标准化的数据可能导致重复, 而且有更大的导致数据不一致的可能性, 但当用户的数据量达到数十 TB 到 PB 级别时, 相对于这些局限性而言, 优化主席那个速度显得更加重要

#### 同一份数据多种处理
Hive 本身提供了一个独特的语法, 支持从一个数据源产生多个数据聚合, 而无需每次聚合都要重新扫描一次, 对于大的数据量的输入, 这个优化可以节约非常可观的时间
```
insert overwrite table sales select from history where action = 'purchaseed';
insert overwrite table credits select from history where action = 'returned';
```
以上语句会从源表 history 表读取数据, 然后导入到 2 张表中, 但因为扫描两遍 history 表而执行效率低下; 以下语句可以达到同样的目的, 却只需扫描一遍就可以
```
from history
insert overwrite table sales select * where action = 'purchaseed'
insert overwrite table credits select * where action = 'returned';
```

#### 对于每个表的分区
很多 ETL 处理过程会涉及到多个处理步骤, 每个步骤可能会产生一个或多个临时表, 这些表仅供下一个 job 使用; 对这些临时表进行分区可以避免在某一步出错时需要重新执行每一天分区数据的处理

#### 分桶表数据存储
分区提供了一个隔离数据和优化查询的便利方式, 但并非所有的数据集都可形成合理的分区; 当分区不合适时可能会造成很多小文件, 使用动态分区时由于 Hive 会限制创建最大分区数可能会失败; 那么则可以考虑进行分桶
```
create table weblog (user_id, int, url string, source_ip string)
partition by (dt string)
cluster by (user_id) into 96 buckets;
```
为了在分桶表中正确的插入数据, 我们需要设置一个属性来强制 Hive 为目标表的分桶初始化过程设置一个正确的 reducer 个数, 然后再执行一个查询来填充分区
```
set hive.enforce.bucketing = true;

from raw_log
insert overwrite table weblog
partition (dt = '2009-09-25')
select user_id, url, source_ip where dt = '2009-09-25';
```
如果没有使用 hive.enforce.bucketing 属性, 那么就需要设置和分通数相匹配的 reducer 个数; 即使用 set mapred.reduce.tasks = 96, 然后在 select 语句后增加 cluster by 语句

#### 为表增加列
Hive 允许在原始数据文件之上定义一个模式, 这样分离的好处是当为文件增加新的字段时, 可以很容易的适应表定义的模式; Hive 提供了 SerDe 抽象, 用于从输入中提取数据, SerDe 同样用于输出数据; 一个 SerDe 通常是从左到右进行解析的, 通过指定的分隔符将行分解成列; SerDe 通常是非常宽松的: 如果某行的字段个数比预期的要少, 那么缺少的字段将会返回 null, 如果某行的字段个数比预期的要多, 那么多处的字段将会被省略掉; 增加新的字段的命令只需要一条 alter table add column 就可以完成, 需要注意的是这种方式无法在已有字段的开始或中间增加字段

#### 使用列存储表
Hive 通常使用行式存储, 但也提供了一个列式的 SerDe 来以混合列式格式存储信息

##### 重复数据
TODO

#### (几乎) 总是使用压缩
几乎在所有情况下, 压缩都可以使磁盘上存储的数据量变小, 这样可以通过降低 I/O 来提高查询执行速度; MapReduce 任务往往是 I/O 密集型的, 因此 CPU 开销通常不是瓶颈
