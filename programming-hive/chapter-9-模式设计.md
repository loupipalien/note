### 模式设计

#### 按天划分的表
按天划分的表是一种模式, 通常会在表名中加入一个时间戳; 在 Hive 中这种情况下应该使用分区表, 通过 where 子句的表达式来选择查询所需要的指定的分区, 这样查询效率较高而且看起来比较清晰明了

#### 关于分区
Hive 通常要对输入进行全盘扫描, 来满足查询条件; 通过创建很多的分区确实可以优化一些查询, 但同时可能会对包含很多小文件的表查询不利; MapReduce 会将一个作业 (job) 转换为多个任务 (task), 默认情况下每个 task 都是一个新的 JVM 实例, 都需要开启和销毁的开销; 对于小文件, 每个文件都会应对一个 task, 在一些情况下 JVM 的开启和销毁的时间可能会比实际处理数据的时间消耗要长  
因此一个理想的分区方案不应该导致产生太多的分区和文件目录, 并且每个目录下的文件应该足够大, 应该是文件系统中块大小的若干倍; 按时间范围进行分区的一个好的策略就是按照不同的时间粒度来确定合适大小的数据累积量, 另一个解决方案是使对多级别分区; 如果不能够找到好的, 大小相对合适的分区方式的话, 可以考虑分桶存储

#### 唯一键和标准化
关系型数据库通常使用唯一键, 索引和标准化来存储数据集; 然而 Hive 没有主键或基于序列密钥生成的自增主键的概念, 并且支持复杂的数据类型, 所以应避免对其非标准化的数据进行连接操作; 避免标准化的主要原因是为了最小化磁盘寻道, 非标准化的数据允许被扫描或写入到大的, 连续的磁盘存储区域, 从而优化磁盘驱动器的 I/O 性能; 虽然非标准化的数据可能导致重复, 而且有更大的导致数据不一致的可能性, 但当用户的数据量达到数十 TB 到 PB 级别时, 相对于这些局限性而言, 优化主席那个速度显得更加重要

#### 同一份数据多种处理
Hive 本身提供了一个独特的语法, 支持从一个数据源产生多个数据聚合, 而无需每次聚合都要重新扫描一次, 对于大的数据量的输入, 这个优化可以节约非常可观的时间
```
insert overwrite table sales select from history where action = 'purchaseed';
insert overwrite table credits select from history where action = 'returned';
```
以上语句会从源表 history 表读取数据, 然后导入到 2 张表中, 但因为扫描两遍 history 表而执行效率低下; 以下语句可以达到同样的目的, 却只需扫描一遍就可以
```
from history
insert overwrite table sales select * where action = 'purchaseed'
insert overwrite table credits select * where action = 'returned';
```

#### 对于每个表的分区
很多 ETL 处理过程会涉及到多个处理步骤, 每个步骤可能会产生一个或多个临时表, 这些表仅供下一个 job 使用; 对这些临时表进行分区可以避免在某一步出错时需要重新执行每一天分区数据的处理

#### 分桶表数据存储
